{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tcga = \"/lustre/groups/shared/users/peng_marr/HistoDINO/logs/DINOv2_finetuned/dinov2_vits_TCGA_training_29999_teacher_checkpoint.pth\"\n",
    "model_nct = \"/lustre/groups/shared/users/peng_marr/HistoDINO/logs/DINOv2_finetuned/dinov2_vits_NCT_10k_training_1999_teacher_checkpoint.pth\"\n",
    "model_tcga_brca = \"/lustre/groups/shared/users/peng_marr/HistoDINO/vits14_brca/training_29999/teacher_checkpoint.pth\"\n",
    "model_tcga_nsclc = \"/lustre/groups/shared/users/peng_marr/HistoDINO/vits14_nsclc/training_29999/teacher_checkpoint.pth\"\n",
    "model_paths = [\n",
    "    # model_tcga, \n",
    "    # model_nct, \n",
    "    model_tcga_brca, \n",
    "    model_tcga_nsclc\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = len(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(model_tcga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the uniform soup sequentially to not overload memory\n",
    "for j, model_path in enumerate(model_paths):\n",
    "\n",
    "    print(f'Adding model {j} of {NUM_MODELS - 1} to uniform soup.')\n",
    "\n",
    "    assert os.path.exists(model_path)\n",
    "    state_dict = torch.load(model_path)['teacher']\n",
    "    if j == 0:\n",
    "        uniform_soup = {k : v * (1./NUM_MODELS) for k, v in state_dict.items()}\n",
    "    else:\n",
    "        uniform_soup = {k : v * (1./NUM_MODELS) + uniform_soup[k] for k, v in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {'teacher': uniform_soup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/lustre/groups/shared/users/peng_marr/HistoDINO/logs/merged_models/dinov2_finetuned_vits14_TCGA-BRCA-NSCLC_uniform_soup.pth\"\n",
    "torch.save(ckpt, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dino_finetuned_downloaded(model_path,modelname):\n",
    "    # pos_embed has wrong shape\n",
    "    model = torch.hub.load(\"facebookresearch/dinov2\", modelname)\n",
    "    # model=torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14')\n",
    "    # load finetuned weights\n",
    "    if model_path is not None:\n",
    "        pretrained = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "        # make correct state dict for loading\n",
    "        new_state_dict = {}\n",
    "        for key, value in pretrained[\"teacher\"].items():\n",
    "            if \"dino_head\" in key or \"ibot_head\" in key:\n",
    "                pass\n",
    "            else:\n",
    "                new_key = key.replace(\"backbone.\", \"\")\n",
    "                new_state_dict[new_key] = value\n",
    "        # change shape of pos_embed\n",
    "        pos_embed = nn.Parameter(torch.zeros(1, 257, 384))\n",
    "        # pos_embed = nn.Parameter(torch.zeros(1, 257, 1536))\n",
    "        model.pos_embed = pos_embed\n",
    "        # load state dict\n",
    "        model.load_state_dict(new_state_dict, strict=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/lustre/groups/shared/users/peng_marr/HistoDINO/logs/merged_models/dinov2_finetuned_vits_TCGA_NCT_uniform_soup.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_dino_finetuned_downloaded(save_path, \"dinov2_vits14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 224, 224).cuda()\n",
    "model = model.cuda()\n",
    "with torch.no_grad():\n",
    "    out = model(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
