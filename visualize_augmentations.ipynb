{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torchvision.transforms.functional as f\n",
    "import torch\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize current DINO augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = \"/home/haicu/sophia.wagner/datasets/TCGA_all_20X_1024px.txt\"\n",
    "patches = np.loadtxt(patches, dtype=str).tolist()\n",
    "# patches = list(Path(\"/lustre/groups/shared/histology_data/TCGA/ACC/patches\").glob(\"**/*.h5\"))\n",
    "# patches = list(Path(\"/lustre/groups/shared/tcga/CRC/patches/512px_crc_wonorm_complete_diag_frozen\").glob(\"**/*.jpeg\"))\n",
    "# patches = np.loadtxt(\"/lustre/groups/shared/histology_data/TCGA/CRC/patches/512px_crc_wonorm_complete_diag_frozen.txt\", dtype=str, max_rows=100).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dinov2.data import DataAugmentationDINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = DataAugmentationDINO(\n",
    "    (1., 1.), #cfg.crops.global_crops_scale,\n",
    "    (0.32, 0.32), #cfg.crops.local_crops_scale,\n",
    "    8, #cfg.crops.local_crops_number,\n",
    "    224, #global_crops_size=cfg.crops.global_crops_size,\n",
    "    local_crops_size=98, #cfg.crops.local_crops_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = np.random.randint(0, len(patches))\n",
    "patch = Image.open(patches[id]).convert(mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = data_transform(patch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 2))\n",
    "for i in range(2):\n",
    "    rev = inverse_normalize(tensor=out[f'global_crops'][i], mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    img = f.to_pil_image(rev)\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(img)\n",
    "    # plt.axis('off')\n",
    "for k in range(8):\n",
    "    rev = inverse_normalize(tensor=out[f'local_crops'][k], mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    img = f.to_pil_image(rev)\n",
    "    plt.subplot(1, 10, k+3)\n",
    "    plt.imshow(img)\n",
    "    # plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether you want to plot local or global crops\n",
    "# global crop 0 and 1 have different settings, local crops are all the same\n",
    "def process_image(index):\n",
    "    out = data_transform(patch)\n",
    "    rev = inverse_normalize(tensor=out[f'global_crops'][1], mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    img = f.to_pil_image(rev)\n",
    "\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the global crops\n",
    "num_images = 10\n",
    "\n",
    "# Create a figure and set the size\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Map the process_image function to each index in parallel\n",
    "    executor.map(process_image, range(num_images))\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list of patches\n",
    "PATH = \"/lustre/groups/shared/histology_data/tcga_patches/patches/2.0\"\n",
    "patches = list(Path(PATH).glob(\"**/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/haicu/sophia.wagner/datasets/TCGA_all_20X_1024px.txt\", patches, fmt=\"%s\", delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
