{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torchvision.transforms.functional as f\n",
    "import torch\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize current DINO augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches = \"/home/haicu/sophia.wagner/datasets/TCGA_all_20X_1024px.txt\"\n",
    "patches = \"/lustre/groups/shared/histology_data/patch_lists/all.txt\"\n",
    "patches = np.loadtxt(patches, dtype=str).tolist()\n",
    "# patches = list(Path(\"/lustre/groups/shared/histology_data/TCGA/ACC/patches\").glob(\"**/*.h5\"))\n",
    "# patches = list(Path(\"/lustre/groups/shared/tcga/CRC/patches/512px_crc_wonorm_complete_diag_frozen\").glob(\"**/*.jpeg\"))\n",
    "# patches = np.loadtxt(\"/lustre/groups/shared/histology_data/TCGA/CRC/patches/512px_crc_wonorm_complete_diag_frozen.txt\", dtype=str, max_rows=100).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dinov2.data import DataAugmentationDINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = DataAugmentationDINO(\n",
    "    (1., 1.), #cfg.crops.global_crops_scale,\n",
    "    (0.32, 0.32), #cfg.crops.local_crops_scale,\n",
    "    8, #cfg.crops.local_crops_number,\n",
    "    224, #global_crops_size=cfg.crops.global_crops_size,\n",
    "    local_crops_size=98, #cfg.crops.local_crops_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = np.random.randint(0, len(patches))\n",
    "patch = Image.open(patches[id]).convert(mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = data_transform(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 2))\n",
    "for i in range(2):\n",
    "    rev = inverse_normalize(tensor=out[f'global_crops'][i], mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    img = f.to_pil_image(rev)\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(img)\n",
    "    # plt.axis('off')\n",
    "for k in range(8):\n",
    "    rev = inverse_normalize(tensor=out[f'local_crops'][k], mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    img = f.to_pil_image(rev)\n",
    "    plt.subplot(1, 10, k+3)\n",
    "    plt.imshow(img)\n",
    "    # plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether you want to plot local or global crops\n",
    "# global crop 0 and 1 have different settings, local crops are all the same\n",
    "def process_image(index):\n",
    "    out = data_transform(patch)\n",
    "    rev = inverse_normalize(tensor=out[f'global_crops'][1], mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    img = f.to_pil_image(rev)\n",
    "\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the global crops\n",
    "num_images = 10\n",
    "\n",
    "# Create a figure and set the size\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Map the process_image function to each index in parallel\n",
    "    executor.map(process_image, range(num_images))\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from  https://github.com/DIAGNijmegen/pathology-he-auto-augment/blob/main/he-randaugment/custom_hed_transform.py\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from skimage.util import dtype, dtype_limits\n",
    "from skimage.exposure import rescale_intensity\n",
    "import time\n",
    "\n",
    "rgb_from_hed = np.array([[0.65, 0.70, 0.29],\n",
    "                         [0.07, 0.99, 0.11],\n",
    "                         [0.27, 0.57, 0.78]]).astype('float32')\n",
    "hed_from_rgb = linalg.inv(rgb_from_hed).astype('float32')\n",
    "\n",
    "\n",
    "def rgb2hed(rgb):\n",
    "\n",
    "    return separate_stains(rgb, hed_from_rgb)\n",
    "\n",
    "def hed2rgb(hed):\n",
    "\n",
    "    return combine_stains(hed, rgb_from_hed)\n",
    "\n",
    "def separate_stains(rgb, conv_matrix):\n",
    "\n",
    "    rgb = dtype.img_as_float(rgb, force_copy=True).astype('float32')\n",
    "    rgb += 2\n",
    "    stains = np.dot(np.reshape(-np.log(rgb), (-1, 3)), conv_matrix)\n",
    "    return np.reshape(stains, rgb.shape)\n",
    "\n",
    "\n",
    "def combine_stains(stains, conv_matrix):\n",
    "\n",
    "\n",
    "    stains = dtype.img_as_float(stains.astype('float64')).astype('float32')  # stains are out of range [-1, 1] so dtype.img_as_float complains if not float64\n",
    "    logrgb2 = np.dot(-np.reshape(stains, (-1, 3)), conv_matrix)\n",
    "    rgb2 = np.exp(logrgb2)\n",
    "    return rescale_intensity(np.reshape(rgb2 - 2, stains.shape),\n",
    "                             in_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_image = np.array(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HED color augmentations adapted from  https://github.com/DIAGNijmegen/pathology-he-auto-augment/blob/main/he-randaugment/custom_hed_transform.py\n",
    "# Tellez et al.\n",
    "__cutoff_range = (0.15, 0.85)\n",
    "\n",
    "def hed_jitter(factor):\n",
    "    __biases = [np.random.uniform(-factor, factor), np.random.uniform(-factor, factor), np.random.uniform(-factor, factor)]\n",
    "    __sigmas = [np.random.uniform(-factor, factor), np.random.uniform(-factor, factor), np.random.uniform(-factor, factor)]\n",
    "\n",
    "    patch_mean = np.mean(a=patch) / 255.0\n",
    "    if __cutoff_range[0] <= patch_mean <= __cutoff_range[1]:\n",
    "        # Reorder the patch to channel last format and convert the image patch to HED color coding.\n",
    "        #\n",
    "        # patch_image = np.transpose(a=patch_image, axes=(1, 2, 0))\n",
    "        patch_hed = rgb2hed(rgb=patch_image)\n",
    "\n",
    "        # Augment the Haematoxylin channel.\n",
    "        #\n",
    "        if __sigmas[0] != 0.0:\n",
    "            patch_hed[:, :, 0] *= (1.0 + __sigmas[0])\n",
    "\n",
    "        if __biases[0] != 0.0:\n",
    "            patch_hed[:, :, 0] += __biases[0]\n",
    "\n",
    "        # Augment the Eosin channel.\n",
    "        #\n",
    "        if __sigmas[1] != 0.0:\n",
    "            patch_hed[:, :, 1] *= (1.0 + __sigmas[1])\n",
    "\n",
    "        if __biases[1] != 0.0:\n",
    "            patch_hed[:, :, 1] += __biases[1]\n",
    "\n",
    "        # Augment the DAB channel.\n",
    "        #\n",
    "        if __sigmas[2] != 0.0:\n",
    "            patch_hed[:, :, 2] *= (1.0 + __sigmas[2])\n",
    "\n",
    "        if __biases[2] != 0.0:\n",
    "            patch_hed[:, :, 2] += __biases[2]\n",
    "        # Convert back to RGB color coding and order back to channels first order.\n",
    "        #\n",
    "        patch_rgb = hed2rgb(hed=patch_hed)\n",
    "        patch_rgb = np.clip(a=patch_rgb, a_min=0.0, a_max=1.0)\n",
    "        patch_rgb *= 255.0\n",
    "        patch_rgb = patch_rgb.astype(dtype=np.uint8)\n",
    "\n",
    "        # patch_transformed = np.transpose(a=patch_rgb, axes=(2, 0, 1))\n",
    "        patch_transformed = patch_rgb\n",
    "    return patch_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 2))\n",
    "plt.subplot(1, 10, 1)\n",
    "plt.imshow(patch)\n",
    "plt.axis('off')\n",
    "for i in tqdm(range(9)):\n",
    "    plt.subplot(1, 10, i + 2)\n",
    "    patch_transformed = hed_jitter(0.05)\n",
    "    plt.imshow(patch_transformed)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list of patches\n",
    "PATH = \"/lustre/groups/shared/histology_data/tcga_patches/patches/2.0\"\n",
    "patches = list(Path(PATH).glob(\"**/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"/home/haicu/sophia.wagner/datasets/TCGA_all_20X_1024px.txt\", patches, fmt=\"%s\", delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
